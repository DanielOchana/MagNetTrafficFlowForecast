{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/danielochana/anaconda3/envs/env3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import networkx as nx\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from math import sqrt \n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1681
        },
        "id": "1H--VekIxYH7",
        "outputId": "4359b80e-b7ba-457c-8aa5-d20cbceb1e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1458644, 11)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>vendor_id</th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>dropoff_datetime</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>store_and_fwd_flag</th>\n",
              "      <th>trip_duration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id2875421</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-03-14 17:24:55</td>\n",
              "      <td>2016-03-14 17:32:30</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.982155</td>\n",
              "      <td>40.767937</td>\n",
              "      <td>-73.964630</td>\n",
              "      <td>40.765602</td>\n",
              "      <td>N</td>\n",
              "      <td>455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id2377394</td>\n",
              "      <td>1</td>\n",
              "      <td>2016-06-12 00:43:35</td>\n",
              "      <td>2016-06-12 00:54:38</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.980415</td>\n",
              "      <td>40.738564</td>\n",
              "      <td>-73.999481</td>\n",
              "      <td>40.731152</td>\n",
              "      <td>N</td>\n",
              "      <td>663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id3858529</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-01-19 11:35:24</td>\n",
              "      <td>2016-01-19 12:10:48</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.979027</td>\n",
              "      <td>40.763939</td>\n",
              "      <td>-74.005333</td>\n",
              "      <td>40.710087</td>\n",
              "      <td>N</td>\n",
              "      <td>2124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id3504673</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-04-06 19:32:31</td>\n",
              "      <td>2016-04-06 19:39:40</td>\n",
              "      <td>1</td>\n",
              "      <td>-74.010040</td>\n",
              "      <td>40.719971</td>\n",
              "      <td>-74.012268</td>\n",
              "      <td>40.706718</td>\n",
              "      <td>N</td>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id2181028</td>\n",
              "      <td>2</td>\n",
              "      <td>2016-03-26 13:30:55</td>\n",
              "      <td>2016-03-26 13:38:10</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.973053</td>\n",
              "      <td>40.793209</td>\n",
              "      <td>-73.972923</td>\n",
              "      <td>40.782520</td>\n",
              "      <td>N</td>\n",
              "      <td>435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  vendor_id      pickup_datetime     dropoff_datetime  \\\n",
              "0  id2875421          2  2016-03-14 17:24:55  2016-03-14 17:32:30   \n",
              "1  id2377394          1  2016-06-12 00:43:35  2016-06-12 00:54:38   \n",
              "2  id3858529          2  2016-01-19 11:35:24  2016-01-19 12:10:48   \n",
              "3  id3504673          2  2016-04-06 19:32:31  2016-04-06 19:39:40   \n",
              "4  id2181028          2  2016-03-26 13:30:55  2016-03-26 13:38:10   \n",
              "\n",
              "   passenger_count  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
              "0                1        -73.982155        40.767937         -73.964630   \n",
              "1                1        -73.980415        40.738564         -73.999481   \n",
              "2                1        -73.979027        40.763939         -74.005333   \n",
              "3                1        -74.010040        40.719971         -74.012268   \n",
              "4                1        -73.973053        40.793209         -73.972923   \n",
              "\n",
              "   dropoff_latitude store_and_fwd_flag  trip_duration  \n",
              "0         40.765602                  N            455  \n",
              "1         40.731152                  N            663  \n",
              "2         40.710087                  N           2124  \n",
              "3         40.706718                  N            429  \n",
              "4         40.782520                  N            435  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the CSV file into a DataFrame\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "\n",
        "# Display the first five rows of the DataFrame\n",
        "print(data.shape)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the pickup and dropoff timestamps to datetime objects\n",
        "data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'])\n",
        "data['dropoff_datetime'] = pd.to_datetime(data['dropoff_datetime'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "data2_5=copy.deepcopy(data)\n",
        "data2_5['pickup_longitude'] = data2_5['pickup_longitude'].apply(lambda x: round(x / 0.005) * 0.005)\n",
        "data2_5['pickup_latitude'] = data2_5['pickup_latitude'].apply(lambda x: round(x / 0.005) * 0.005)\n",
        "data2_5['dropoff_longitude'] = data2_5['dropoff_longitude'].apply(lambda x: round(x / 0.005) * 0.005)\n",
        "data2_5['dropoff_latitude'] = data2_5['dropoff_latitude'].apply(lambda x: round(x / 0.005) *0.005)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###\n",
        "repeat \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "data_all_slots = {}\n",
        "slot = 0\n",
        "for day in (4,5, 6):\n",
        "    # Define the start and end timestamps for the day\n",
        "    start_timestamp = pd.Timestamp(f'2016-01-0{day} 06:00:00')\n",
        "    end_timestamp = pd.Timestamp(f'2016-01-0{day} 23:59:59')\n",
        "\n",
        "    # Generate 6 timestamps, each with a different 3-hour timeslot\n",
        "    timestamps = pd.date_range(start=start_timestamp, end=end_timestamp, freq='3H')[:6]\n",
        "\n",
        "    # Create 15 copies of data2_5 with different timeslots\n",
        "    for timestamp in timestamps:\n",
        "        start_time = timestamp\n",
        "        end_time = timestamp + pd.Timedelta(hours=3)\n",
        "        copy = data2_5[(data2_5['pickup_datetime'] >= start_time) & (data2_5['pickup_datetime'] < end_time)].copy()\n",
        "        data_all_slots[slot]=(copy)\n",
        "        slot += 1\n",
        "\n",
        "\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18\n"
          ]
        }
      ],
      "source": [
        "print (len(data_all_slots))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calc_air_distance(lat1, lon1, lat2, lon2):\n",
        "    # Assuming 1 degree of latitude and longitude is approximately 111 kilometers\n",
        "    lat_km = 111.0\n",
        "    lon_km = 90.0\n",
        "\n",
        "    # Calculate the difference in coordinates\n",
        "    delta_lat = lat2 - lat1\n",
        "    delta_lon = lon2 - lon1\n",
        "\n",
        "    # Calculate the distance using Euclidean distance formula\n",
        "    distance = sqrt((delta_lat * lat_km)**2 + (delta_lon * lon_km)**2)\n",
        "    return distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num of self loops in data = 12\n",
            "num of self loops in data = 10\n",
            "num of self loops in data = 23\n",
            "num of self loops in data = 17\n",
            "num of self loops in data = 20\n",
            "num of self loops in data = 17\n",
            "num of self loops in data = 23\n",
            "num of self loops in data = 20\n",
            "num of self loops in data = 12\n",
            "num of self loops in data = 18\n",
            "num of self loops in data = 20\n",
            "num of self loops in data = 6\n",
            "num of self loops in data = 9\n",
            "num of self loops in data = 16\n",
            "num of self loops in data = 19\n",
            "num of self loops in data = 20\n",
            "num of self loops in data = 17\n",
            "num of self loops in data = 15\n"
          ]
        }
      ],
      "source": [
        "# Create a dictionary to store the directed graphs\n",
        "graphs = {}\n",
        "\n",
        "# Loop through each data in data_all_slots\n",
        "for key, data in data_all_slots.items():\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "    selfloops = 0\n",
        "    # Add edges to the graph\n",
        "    for row in data.itertuples():\n",
        "        source = (row.pickup_longitude, row.pickup_latitude)\n",
        "        destination = (row.dropoff_longitude, row.dropoff_latitude)\n",
        "        distance = calc_air_distance(row.dropoff_latitude, row.dropoff_longitude, row.pickup_latitude, row.pickup_longitude)\n",
        "        speed = 3600 * distance / row.trip_duration\n",
        "        edge_data = {'weight': speed, 'datetime': row.pickup_datetime}\n",
        "        if source != destination:\n",
        "            G.add_edge(source, destination, **edge_data)\n",
        "        else:\n",
        "            selfloops += 1\n",
        "    print(f'num of self loops in data = {selfloops}')\n",
        "    # Add the graph to the dictionary\n",
        "    graphs[key] = G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create a dictionary to store the directed graphs\n",
        "graphs = {}\n",
        "\n",
        "# Loop through each data in data_all_slots\n",
        "for key, data in data_all_slots.items():\n",
        "    # Create a directed graph\n",
        "    G = nx.DiGraph()\n",
        "    selfloops = 0\n",
        "    # Add edges to the graph\n",
        "    for row in data.itertuples():\n",
        "        source = (row.pickup_longitude, row.pickup_latitude)\n",
        "        destination = (row.dropoff_longitude, row.dropoff_latitude)\n",
        "        distance = calc_air_distance(row.dropoff_latitude, row.dropoff_longitude, row.pickup_latitude, row.pickup_longitude)\n",
        "        weight =3600*( distance /row.trip_duration )\n",
        "        if source != destination:\n",
        "            G.add_edge(source, destination, weight=weight)\n",
        "        else :\n",
        "            selfloops+=1\n",
        "    print(f'num of self loops in data = {selfloops}')\n",
        "    # Add the graph to the dictionary\n",
        "    graphs[key] = G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a directory to store the CSV files\n",
        "os.makedirs('data_all_slots_csv/data_csv', exist_ok=True)\n",
        "\n",
        "# Iterate over the data_all_slots dictionary\n",
        "for key, data in data_all_slots.items():\n",
        "    # Generate the file path\n",
        "    file_path = f'data_all_slots_csv/data_{key}.csv'\n",
        "    \n",
        "    # Save the DataFrame as a CSV file\n",
        "    data.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.makedirs('data_all_slots_csv/adj_matrices', exist_ok=True)\n",
        "for key, G in graphs.items():\n",
        "    A = nx.adjacency_matrix(G,  weight = 'weight')\n",
        "    # Convert the matrix A to a DataFrame\n",
        "    df_A = pd.DataFrame.sparse.from_spmatrix(A)\n",
        "    # Save the DataFrame as a CSV file\n",
        "    df_A.to_csv(f'data_all_slots_csv/adj_matrices/Adj_{key}.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "129\n"
          ]
        }
      ],
      "source": [
        "common_nodes = set(graphs[0].nodes())\n",
        "for key, graph in graphs.items():\n",
        "    common_nodes = common_nodes.intersection(set(graph.nodes()))\n",
        "\n",
        "num_common_nodes = len(common_nodes)\n",
        "print(num_common_nodes)\n",
        "\n",
        "# Remove nodes that are not common to all graphs\n",
        "for key, graph in graphs.items():\n",
        "    graph.remove_nodes_from(set(graph.nodes()) - common_nodes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph 0: Number of nodes = 129, Number of edges = 679\n",
            "Graph 1: Number of nodes = 129, Number of edges = 719\n",
            "Graph 2: Number of nodes = 129, Number of edges = 729\n",
            "Graph 3: Number of nodes = 129, Number of edges = 798\n",
            "Graph 4: Number of nodes = 129, Number of edges = 973\n",
            "Graph 5: Number of nodes = 129, Number of edges = 551\n",
            "Graph 6: Number of nodes = 129, Number of edges = 723\n",
            "Graph 7: Number of nodes = 129, Number of edges = 801\n",
            "Graph 8: Number of nodes = 129, Number of edges = 800\n",
            "Graph 9: Number of nodes = 129, Number of edges = 859\n",
            "Graph 10: Number of nodes = 129, Number of edges = 948\n",
            "Graph 11: Number of nodes = 129, Number of edges = 639\n",
            "Graph 12: Number of nodes = 129, Number of edges = 706\n",
            "Graph 13: Number of nodes = 129, Number of edges = 835\n",
            "Graph 14: Number of nodes = 129, Number of edges = 822\n",
            "Graph 15: Number of nodes = 129, Number of edges = 812\n",
            "Graph 16: Number of nodes = 129, Number of edges = 1037\n",
            "Graph 17: Number of nodes = 129, Number of edges = 738\n"
          ]
        }
      ],
      "source": [
        "for key, graph in graphs.items():\n",
        "    num_nodes = graph.number_of_nodes()\n",
        "    num_edges = graph.number_of_edges()\n",
        "    print(f\"Graph {key}: Number of nodes = {num_nodes}, Number of edges = {num_edges}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "# Create a directory to store the CSV files\n",
        "os.makedirs('data_common_slots_csv/data_csv', exist_ok=True)\n",
        "\n",
        "# Iterate over the data_all_slots dictionary\n",
        "for key, data in data_all_slots.items():\n",
        "    # Generate the file path\n",
        "    file_path = f'data_common_slots_csv/data_csv/data_{key}.csv'\n",
        "    \n",
        "    # Save the DataFrame as a CSV file\n",
        "    data.to_csv(file_path, index=False)\n",
        "\n",
        "os.makedirs('data_common_slots_csv/adj_matrices', exist_ok=True)\n",
        "for key, G in graphs.items():\n",
        "    A = nx.adjacency_matrix(G,  weight = 'weight')\n",
        "    # Convert the matrix A to a DataFrame\n",
        "    df_A = pd.DataFrame.sparse.from_spmatrix(A)\n",
        "    # Save the DataFrame as a CSV file\n",
        "    df_A.to_csv(f'data_common_slots_csv/adj_matrices/Adj_{key}.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "vscode": {
          "languageId": "ruby"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file 'edges_info.csv' has been created.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "# Define the file path\n",
        "file_path = 'edges_info.csv'\n",
        "\n",
        "# Define the headers for the CSV file\n",
        "headers = ['Dropoff Longitude', 'Dropoff Latitude', 'Pickup Longitude', 'Pickup Latitude', 'Speed', 'Time']\n",
        "\n",
        "# Open the CSV file in write mode\n",
        "with open(file_path, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    \n",
        "    # Write the headers to the CSV file\n",
        "    writer.writerow(headers)\n",
        "    for key, G in graphs.items():\n",
        "        # Iterate over each edge in the graph\n",
        "        for edge in G.edges(data=True):\n",
        "            # Extract the edge information\n",
        "            dropoff_longitude = edge[0][0]\n",
        "            dropoff_latitude = edge[0][1]\n",
        "            pickup_longitude = edge[1][0]\n",
        "            pickup_latitude = edge[1][1]\n",
        "            speed = edge[2]['weight']\n",
        "            time = edge[2]['datetime']\n",
        "        \n",
        "            # Write the edge information to the CSV file\n",
        "            writer.writerow([dropoff_longitude, dropoff_latitude, pickup_longitude, pickup_latitude, speed, time])\n",
        "\n",
        "print(f\"CSV file '{file_path}' has been created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "non_directed_graphs = {}\n",
        "\n",
        "# Loop through each graph in the graphs dictionary\n",
        "for key, graph in graphs.items():\n",
        "    # Create a non-directed version of the graph\n",
        "    non_directed_graph = graph.to_undirected()\n",
        "    \n",
        "    # Add the non-directed graph to the dictionary\n",
        "    non_directed_graphs[key] = non_directed_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loop through each graph in the non_directed_graphs dictionary\n",
        "for key, graph in non_directed_graphs.items():\n",
        "    # Loop through each edge in the graph\n",
        "    for edge in graph.edges(data=True):\n",
        "        # Set the weight of the edge to 1\n",
        "        edge[2]['weight'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a directory to store the non-directed graph information\n",
        "os.makedirs('non_directed_graph_info', exist_ok=True)\n",
        "\n",
        "# Save the adjacency matrix of all graphs\n",
        "for key, graph in non_directed_graphs.items():\n",
        "    A = nx.adjacency_matrix(graph, weight='weight')\n",
        "    # Convert the matrix A to a DataFrame\n",
        "    df_A = pd.DataFrame.sparse.from_spmatrix(A)\n",
        "    # Save the DataFrame as a CSV file\n",
        "    df_A.to_csv(f'non_directed_graph_info/Adj_{key}.csv', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n",
            "(129, 129)\n"
          ]
        }
      ],
      "source": [
        "for key, graph in non_directed_graphs.items():\n",
        "    A = nx.adjacency_matrix(graph, weight='weight')\n",
        "    df_A = pd.DataFrame.sparse.from_spmatrix(A)\n",
        "    print (df_A.shape)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file 'non_directed_graph_info/ID_edges_info.csv' has been created.\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        " \n",
        "# Define the file path for the edges_info.csv file\n",
        "edges_file_path = 'non_directed_graph_info/ID_edges_info.csv'\n",
        "\n",
        "# Define the headers for the CSV file\n",
        "headers = ['ID1', 'ID2', 'datetime']\n",
        "\n",
        "# Open the CSV file in write mode\n",
        "with open(edges_file_path, 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    \n",
        "    # Write the headers to the CSV file\n",
        "    writer.writerow(headers)\n",
        "    \n",
        "    # Assign a unique ID to each node\n",
        "    node_ids = {node: i+1 for i, node in enumerate(common_nodes)}\n",
        "    \n",
        "    # Loop through each graph in the non_directed_graphs dictionary\n",
        "    for key, graph in non_directed_graphs.items():\n",
        "        # Loop through each edge in the graph\n",
        "        for edge in graph.edges(data=True):\n",
        "            # Extract the edge information\n",
        "            node1 = edge[0]\n",
        "            node2 = edge[1]\n",
        "            datetime = edge[2]['datetime']\n",
        "            \n",
        "            # Get the unique IDs for the nodes\n",
        "            id1 = node_ids[node1]\n",
        "            id2 = node_ids[node2]\n",
        "            \n",
        "            # Write the edge information to the CSV file\n",
        "            writer.writerow([id1, id2, datetime])\n",
        "\n",
        "print(f\"CSV file '{edges_file_path}' has been created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
